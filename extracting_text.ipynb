{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "def compute_skew(file_name):\n",
    "    \n",
    "    #load in grayscale:\n",
    "    src = cv2.imread(file_name,0)\n",
    "    height, width = src.shape[0:2]\n",
    "    \n",
    "    #invert the colors of our image:\n",
    "    cv2.bitwise_not(src, src)\n",
    "    \n",
    "    #Hough transform:\n",
    "    minLineLength = width/2.0\n",
    "    maxLineGap = 20\n",
    "    lines = cv2.HoughLinesP(src,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    \n",
    "    #calculate the angle between each line and the horizontal line:\n",
    "    angle = 0.0\n",
    "    nb_lines = len(lines)\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        angle += math.atan2(line[0][3]*1.0 - line[0][1]*1.0,line[0][2]*1.0 - line[0][0]*1.0);\n",
    "    \n",
    "    angle /= nb_lines*1.0\n",
    "    \n",
    "    return angle* 180.0 / np.pi\n",
    "\n",
    "\n",
    "def deskew(file_name,angle):\n",
    "    \n",
    "    #load in grayscale:\n",
    "    img = cv2.imread(file_name,0)\n",
    "    \n",
    "    #invert the colors of our image:\n",
    "    cv2.bitwise_not(img, img)\n",
    "    \n",
    "    #compute the minimum bounding box:\n",
    "    non_zero_pixels = cv2.findNonZero(img)\n",
    "    center, wh, theta = cv2.minAreaRect(non_zero_pixels)\n",
    "    \n",
    "    root_mat = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "    rows, cols = img.shape\n",
    "    rotated = cv2.warpAffine(img, root_mat, (cols, rows), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "    #Border removing:\n",
    "    sizex = np.int0(wh[0])\n",
    "    sizey = np.int0(wh[1])\n",
    "    print(theta)\n",
    "    if theta > -45 :\n",
    "        temp = sizex\n",
    "        sizex= sizey\n",
    "        sizey= temp\n",
    "    return cv2.getRectSubPix(rotated, (sizey,sizex), center)\n",
    "  \n",
    "\n",
    "file_path = 'generated_images/6.jpg'\n",
    "#print(file_path.shape)\n",
    "#rotated = imutils.rotate(cv2.imread(file_path), 90)\n",
    "angel = compute_skew(file_path)\n",
    "dst = deskew(file_path,angel)\n",
    "cv2.imwrite('skew.jpg',dst)\n",
    "\n",
    "#th2 = cv2.adaptiveThreshold(dst,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            #cv2.THRESH_BINARY,11,2)\n",
    "#cv2.imwrite('skew.jpg',th2)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Result\",dst)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "def compute_skew(file_name):\n",
    "    \n",
    "    #load in grayscale:\n",
    "    src = cv2.imread(file_name,0)\n",
    "    height, width = src.shape[0:2]\n",
    "    \n",
    "    #invert the colors of our image:\n",
    "    cv2.bitwise_not(src, src)\n",
    "    \n",
    "    #Hough transform:\n",
    "    minLineLength = width/2.0\n",
    "    maxLineGap = 20\n",
    "    lines = cv2.HoughLinesP(src,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    \n",
    "    #calculate the angle between each line and the horizontal line:\n",
    "    angle = 0.0\n",
    "    nb_lines = len(lines)\n",
    "    \n",
    "    \n",
    "    for line in lines:\n",
    "        angle += math.atan2(line[0][3]*1.0 - line[0][1]*1.0,line[0][2]*1.0 - line[0][0]*1.0);\n",
    "    \n",
    "    angle /= nb_lines*1.0\n",
    "    \n",
    "    return angle* 180.0 / np.pi\n",
    "  \n",
    "\n",
    "def rotate_bound(image, angle):\n",
    "    # grab the dimensions of the image and then determine the\n",
    "    # center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    " \n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))\n",
    "\n",
    "\n",
    "file_path = 'generated_images/1.jpg'\n",
    "#print(file_path.shape)\n",
    "#rotated = imutils.rotate(cv2.imread(file_path), 90)\n",
    "angel = compute_skew(file_path)\n",
    "print(angel)\n",
    "dst = rotate_bound(cv2.imread(file_path),angel)\n",
    "cv2.imwrite('skew.jpg',dst)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(dst,None,10,10,7,21)\n",
    "\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_blur = cv2.medianBlur(dst,5).astype('uint8')\n",
    "img_thresh_Gaussian = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "\n",
    "#cv2.imwrite('skew.jpg',th2)\n",
    "cv2.imwrite('skew.jpg',img_thresh_Gaussian)\n",
    "\n",
    "cv2.imshow(\"Result\",img_thresh_Gaussian)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing step before performing ocr\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "file_path = 'generated_images/11.jpg'\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(cv2.imread(file_path),None,10,10,7,21)\n",
    "\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_blur = cv2.medianBlur(dst,5).astype('uint8')\n",
    "img_thresh_Gaussian = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "\n",
    "cv2.imwrite('skew.jpg',img_thresh_Gaussian)\n",
    "cv2.imshow('skew',img_thresh_Gaussian)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#skew correction which works fine if the angle is not 45\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open(\"hackathon_images/21.png\")\n",
    "im.save(\"skew.jpg\", dpi=(300,300))\n",
    "\n",
    "file_path = 'skew.jpg'\n",
    "print(cv2.imread(file_path).shape)\n",
    "#file_path = 'im_after_text_extraction.jpg'\n",
    "\n",
    "#code to sharpen\n",
    "#kernel_sharp = np.array([[-1,-1,-1],[-1, 9,-1],[-1,-1,-1]])\n",
    "#dst = cv2.filter2D(cv2.imread(file_path),-1,kernel_sharp)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(cv2.imread(file_path),None,10,10,7,21)\n",
    "\n",
    "dst = cv2.medianBlur(dst,5).astype('uint8')\n",
    "dst = cv2.GaussianBlur(dst,(5,5),cv2.BORDER_DEFAULT) \n",
    "\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite('pw.jpg',dst)\n",
    "\n",
    "#cv2.imshow(\"k\", dst)\n",
    "#cv2.waitKey(0)\n",
    "img_thresh_Gaussian = cv2.adaptiveThreshold(dst, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "\n",
    "#img_thresh_Gaussian = cv2.adaptiveThreshold(dst, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "ret2,img_thresh_Gaussian = cv2.threshold(img_thresh_Gaussian,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "#cv2.imshow(\"k\", img_thresh_Gaussian)\n",
    "#cv2.waitKey(0)\n",
    "#img_thresh_Gaussian = cv2.Canny(img_thresh_Gaussian,100,200)\n",
    "\n",
    "cv2.imwrite('skew.jpg',img_thresh_Gaussian)\n",
    "\n",
    "# load the image from disk\n",
    "image = cv2.imread('skew.jpg')\n",
    "\t\n",
    "# convert the image to grayscale and flip the foreground\n",
    "# and background to ensure foreground is now \"white\" and\n",
    "# the background is \"black\"\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = cv2.bitwise_not(gray)\n",
    "\n",
    "\n",
    "# threshold the image, setting all foreground pixels to\n",
    "# 255 and all background pixels to 0\n",
    "thresh = cv2.threshold(gray, 0, 255,\n",
    "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#cv2.imshow(\"Rotated\", thresh)\n",
    "#cv2.waitKey(0)\n",
    "# grab the (x, y) coordinates of all pixel values that\n",
    "# are greater than zero, then use these coordinates to\n",
    "# compute a rotated bounding box that contains all\n",
    "# coordinates\n",
    "coords = np.column_stack(np.where(thresh > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    " \n",
    "# the `cv2.minAreaRect` function returns values in the\n",
    "# range [-90, 0); as the rectangle rotates clockwise the\n",
    "# returned angle trends to 0 -- in this special case we\n",
    "# need to add 90 degrees to the angle\n",
    "if angle < -45:\n",
    "\tangle = -(90 + angle)\n",
    " \n",
    "# otherwise, just take the inverse of the angle to make\n",
    "# it positive\n",
    "else:\n",
    "\tangle = -angle\n",
    "print(angle)\n",
    "\n",
    "if angle> -2 and angle < 5:\n",
    "    angle = 0\n",
    "# rotate the image to deskew it\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h),\n",
    "\tflags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# draw the correction angle on the image so we can validate it\n",
    "#cv2.putText(rotated, \"Angle: {:.2f} degrees\".format(angle),\n",
    "#\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "kernel_sharp = np.array([[-1,-1,-1],[-1, 9,-1],[-1,-1,-1]])\n",
    "rotated = cv2.filter2D(rotated,-1,kernel_sharp)\n",
    "rotated = cv2.medianBlur(rotated,5).astype('uint8')\n",
    "\n",
    "\n",
    "if rotated[0][0][0]!=255 or rotated[0][0][1]!=255 or rotated[0][0][2]!=255:\n",
    "    rotated = cv2.bitwise_not(rotated)\n",
    "\n",
    "rotated = cv2.fastNlMeansDenoising(rotated, None, 9, 13)\n",
    "#dst = cv2.filter2D(rotated,-1,kernel_sharp)\n",
    "#rotated = cv2.fastNlMeansDenoising(rotated, None, 9, 13)\n",
    "#rotated = cv2.resize(rotated,(int(rotated.shape[1]/2),int(rotated.shape[0]/2)))\n",
    "cv2.imwrite('skew.jpg',rotated)\n",
    " \n",
    "im1 = Image.open(\"skew.jpg\")\n",
    "print(pytesseract.image_to_string(im1, lang='eng'))\n",
    "# show the output image\n",
    "#print(\"[INFO] angle: {:.3f}\".format(angle))\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Rotated\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "#kernel_sharp = np.array([[-1,-1,-1],[-1, 9,-1],[-1,-1,-1]])\n",
    "#dst = cv2.filter2D(cv2.imread('hackathon_images/21.png'),-1,kernel_sharp)\n",
    "#cv2.imwrite('hackathon_images/21.png',dst)\n",
    "im1 = Image.open(\"hackathon_images/9.png\")\n",
    "print(pytesseract.image_to_string(im1, lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python text_detection.py --image images/lebron_james.jpg --east frozen_east_text_detection.pb\n",
    "\n",
    "# import the necessary packages\n",
    "import imutils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "#import argparse\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# load the input image and grab the image dimensions\n",
    "image = cv2.imread('fintech2.png')\n",
    "orig = image.copy()\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# set the new width and height and then determine the ratio in change\n",
    "# for both the width and height\n",
    "(newW, newH) = (512,512)\n",
    "rW = W / float(newW)\n",
    "rH = H / float(newH)\n",
    "\n",
    "# resize the image and grab the new image dimensions\n",
    "image = cv2.resize(image, (newW, newH))\n",
    "(H, W) = image.shape[:2]\n",
    "\n",
    "# define the two output layer names for the EAST detector model that\n",
    "# we are interested -- the first is the output probabilities and the\n",
    "# second can be used to derive the bounding box coordinates of text\n",
    "layerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]\n",
    "\n",
    "# load the pre-trained EAST text detector\n",
    "print(\"[INFO] loading EAST text detector...\")\n",
    "net = cv2.dnn.readNet('frozen_east_text_detection.pb')\n",
    "\n",
    "# construct a blob from the image and then perform a forward pass of\n",
    "# the model to obtain the two output layer sets\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "start = time.time()\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "end = time.time()\n",
    "\n",
    "# show timing information on text prediction\n",
    "print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "\n",
    "# grab the number of rows and columns from the scores volume, then\n",
    "# initialize our set of bounding box rectangles and corresponding\n",
    "# confidence scores\n",
    "(numRows, numCols) = scores.shape[2:4]\n",
    "rects = []\n",
    "confidences = []\n",
    "\n",
    "# loop over the number of rows\n",
    "for y in range(0, numRows):\n",
    "\t# extract the scores (probabilities), followed by the geometrical\n",
    "\t# data used to derive potential bounding box coordinates that\n",
    "\t# surround text\n",
    "\tscoresData = scores[0, 0, y]\n",
    "\txData0 = geometry[0, 0, y]\n",
    "\txData1 = geometry[0, 1, y]\n",
    "\txData2 = geometry[0, 2, y]\n",
    "\txData3 = geometry[0, 3, y]\n",
    "\tanglesData = geometry[0, 4, y]\n",
    "\n",
    "\t# loop over the number of columns\n",
    "\tfor x in range(0, numCols):\n",
    "\t\t# if our score does not have sufficient probability, ignore it\n",
    "\t\tif scoresData[x] < 0.7:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# compute the offset factor as our resulting feature maps will\n",
    "\t\t# be 4x smaller than the input image\n",
    "\t\t(offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "\t\t# extract the rotation angle for the prediction and then\n",
    "\t\t# compute the sin and cosine\n",
    "\t\tangle = anglesData[x]\n",
    "\t\tcos = np.cos(angle)\n",
    "\t\tsin = np.sin(angle)\n",
    "\n",
    "\t\t# use the geometry volume to derive the width and height of\n",
    "\t\t# the bounding box\n",
    "\t\th = xData0[x] + xData2[x]\n",
    "\t\tw = xData1[x] + xData3[x]\n",
    "\n",
    "\t\t# compute both the starting and ending (x, y)-coordinates for\n",
    "\t\t# the text prediction bounding box\n",
    "\t\tendX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "\t\tendY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "\t\tstartX = int(endX - w)\n",
    "\t\tstartY = int(endY - h)\n",
    "\n",
    "\t\t# add the bounding box coordinates and probability score to\n",
    "\t\t# our respective lists\n",
    "\t\trects.append((startX, startY, endX, endY))\n",
    "\t\tconfidences.append(scoresData[x])\n",
    "\n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding\n",
    "# boxes\n",
    "boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "k=0\n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in boxes:\n",
    "\t# scale the bounding box coordinates based on the respective\n",
    "\t# ratios\n",
    "\tstartX = int(startX * rW)\n",
    "\tstartY = int(startY * rH)\n",
    "\tendX = int(endX * rW)\n",
    "\tendY = int(endY * rH)\n",
    "\tk = k+1 \n",
    "\tprint(k)\n",
    "\t# draw the bounding box on the image\n",
    "\tim =  orig[startY:endY, startX:endX]\n",
    "\tcv2.imwrite('im_after_text_detection'+ str(k) +'.jpg',im)\n",
    "\tcv2.rectangle(orig, (startX-20, startY-20), (endX+20, endY+20), (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Text Detection\", orig)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('generated_images/1.jpg')\n",
    "img = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "cv2.imshow('segmented',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import color, data, restoration\n",
    "from skimage.io import imsave\n",
    "\n",
    "astro = color.rgb2gray(cv2.imread('pw.jpg'))\n",
    "from scipy.signal import convolve2d as conv2\n",
    "psf = np.ones((5, 5)) / 25\n",
    "astro = conv2(astro, psf, 'same')\n",
    "astro += 0.1 * astro.std() * np.random.standard_normal(astro.shape)\n",
    "\n",
    "deconvolved, _ = restoration.unsupervised_wiener(astro, psf)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 5),\n",
    "                       sharex=True, sharey=True)\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "ax[0].imshow(astro, vmin=deconvolved.min(), vmax=deconvolved.max())\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Data')\n",
    "\n",
    "ax[1].imshow(deconvolved)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Self tuned restoration')\n",
    "\n",
    "imsave('deconvoluted.jpg',deconvolved)\n",
    "cv2.imshow('deconvolved', deconvolved)\n",
    "cv2.waitKey(0)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "im = Image.open(\"fintech.jpg\")\n",
    "im.save(\"skew.jpg\", dpi=(300,300))\n",
    "img = cv2.imread('skew.jpg',0)\n",
    "equ = cv2.equalizeHist(img)\n",
    "res = np.hstack((img,equ)) #stacking images side-by-side\n",
    "#equ = cv2.adaptiveThreshold(equ, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11,2)\n",
    "kernel_sharp = np.array([[-1,-1,-1],[-1, 9,-1],[-1,-1,-1]])\n",
    "equ = cv2.filter2D(equ,-1,kernel_sharp)\n",
    "#thresh = cv2.threshold(equ, 0, 255,\n",
    "#\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "cv2.imwrite('sir1.jpg',equ)\n",
    "\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#threshold_sauvola\n",
    "import pytest\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage as ndi\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage._shared._warnings import expected_warnings\n",
    "from skimage.filters.thresholding import (threshold_local,\n",
    "                                          threshold_otsu,\n",
    "                                          threshold_li,\n",
    "                                          threshold_yen,\n",
    "                                          threshold_isodata,\n",
    "                                          threshold_niblack,\n",
    "                                          threshold_sauvola,\n",
    "                                          threshold_mean,\n",
    "                                          threshold_triangle,\n",
    "                                          threshold_minimum,\n",
    "                                          try_all_threshold,\n",
    "                                          _mean_std)\n",
    "from skimage._shared import testing\n",
    "\"\"\"\n",
    "def threshold_sauvola(image, window_size=15, k=0.2, r=None):\n",
    "    if r is None:\n",
    "        imin, imax = dtype_limits(image, clip_negative=False)\n",
    "        r = 0.5 * (imax - imin)\n",
    "    m, s = _mean_std(image, window_size)\n",
    "    return m * (1 + k * ((s / r) - 1))\n",
    "\"\"\"\n",
    "def test_threshold_sauvola(image):\n",
    "        thres = threshold_sauvola(image, window_size=3)\n",
    "        out = image > thres\n",
    "        return out\n",
    "    \n",
    "image = io.imread('generated_images/4.jpg',0)\n",
    "thresh_sauvola1 = threshold_sauvola(image,3)\n",
    "print(thresh_sauvola1)\n",
    "binary_sauvola = image > thresh_sauvola1\n",
    "binary_sauvola = 1 * binary_sauvola\n",
    "print(binary_sauvola)\n",
    "\n",
    "#img = Image.fromarray(binary_sauvola, 'RGB')\n",
    "#cv2.imshow('g',binary_sauvola)\n",
    "#cv2.waitKey(0)\n",
    "#from scipy.misc import imshow\n",
    "#imshow(binary_sauvola)\n",
    "\n",
    "import scipy.misc\n",
    "scipy.misc.imsave('outfilefff.jpg', binary_sauvola)\n",
    "\n",
    "#plt.imshow(binary_sauvola, cmap=plt.cm.gray)\n",
    "#plt.title('Sauvola Threshold')\n",
    "#plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    " \n",
    " \n",
    "def add_border(input_image, output_image, border):\n",
    "    img = Image.open(input_image)\n",
    " \n",
    "    if isinstance(border, int) or isinstance(border, tuple):\n",
    "        bimg = ImageOps.expand(img, border=border)\n",
    "    else:\n",
    "        raise RuntimeError('Border is not an integer or tuple!')\n",
    " \n",
    "    bimg.save(output_image)\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    in_img = 'fin.png'\n",
    " \n",
    "    add_border(in_img, output_image='butterfly_border.jpg',\n",
    "               border=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
